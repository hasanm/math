\documentclass[12pt]{book}
\usepackage{setspace}
\usepackage{charter}
\usepackage[T1]{fontenc}
\usepackage{url}
% \usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{pifont} 
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf}
\usepackage{calc}

\usepackage[hmargin=20mm,top=20mm, bottom=20mm]{geometry}
\usepackage{tikz}
\usetikzlibrary{intersections,arrows,decorations.pathmorphing,backgrounds,positioning,fit,calc,matrix,3d,chains,petri,through,scopes,shadows,shapes.geometric}
\usepackage{tikz-cd}
% \usepackage[normalem]{ulem} % for Strike out.
\usepackage{physics}
\usepackage{soul} % For Strikethrough
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\code}{\texttt}
\newcommand\T{\rule{0pt}{2.6ex}}
\newcommand\B{\rule[-1.2ex]{0pt}{0pt}}
\newcommand\Pb{\vspace{1.2ex}}
\newtheorem{note}{Note}[section]
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem*{problem*}{Problem}
\newtheorem*{exercise*}{Exercise}
\newtheorem{lemma}{Lemma}
\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand{\LL}{\mathcal{L}}
\newcommand{\interior}{interior}
\newcommand{\tand}{\ \text{and} \ }
\newcommand{\ipp}[2]{\langle #1, #2 \rangle}

% No Indent 
\setlength\parindent{0pt}
\title{Excercise: Linear Algebra\\
\large{Stat 2780, Fall 2024}}
\author{Mahmudul Hasan (hasan@uleth.ca)\\
}
\begin{document}
% \input{ch-intro.tex}
% \maketitle

\chapter{Calculus}
\section{Limits}
\begin{problem*}
  5-9. Prove that $\lim_{x\to a} f(x) = \lim_{h \to 0}f(a+h)$. (This is mainly an exercise in understanding what the terms mean). 
\end{problem*}

\begin{proof}
  \T\B We assume that $f$ is defined in an open neighbourhood containing $a$, but not necessarily at $a$.

  \T\B Suppose $\lim_{x\to a} f(x) = l$. Let $\epsilon > 0$ be arbitrary. There exists $\delta > 0$ such that $\abs{f(x) -l } < \epsilon$ when $0 < \abs{x-a} < \delta$. Let $g(h) = f(a+h)$. Moreover, assume that $-\delta < h < \delta$ except $h \ne 0$. Then we have $a - \delta < a+h < a+\delta$, except $a+h \ne 0$. Then we have $\abs{g(h) -l  } = \abs{f(a+h) -l } <  \epsilon$. Hence $\lim_{h\to 0} g(h) = \lim_{h\to 0} f(a+h) = l$

  \T\B Now suppose $\lim_{h\to 0} g(h) = \lim_{h\to 0} f(a+h) = l$. Let $\epsilon > 0$, then there exists $\delta > 0$ such that $0 < \abs{h} < \delta $, then $\abs{f(a+h) - l } <\epsilon$. Now suppose $0< \abs{x -a} < \delta$. Then we have $\abs{f(a+x -a) -l } = \abs{f(x) -l }< \epsilon$. Therefore, $\lim_{x \to a}f(x) = l$. 
\end{proof}

\begin{problem*}
  \T\B 5-10 (a) Prove that $\lim_{x\to a}f(x) = l$ if and only if $\lim_{x \to a} f(x) -l = 0$.

  \T\B(b)Prove that $\lim_{x \to 0} f(x) = \lim_{x \to a}f(x-a)$.

  \T\B (c) Prove that $\lim_{x \to 0}f(x) = \lim_{x \to 0} f(x^3)$.

  \T\B (d) Give an example where $\lim_{x \to 0} f(x^2) $ exists, but $\lim_{x \to 0}f(x)$ does not. 
\end{problem*}

\begin{problem*}
  \T\B 5-14. (a) Prove that if $\lim_{x \to 0} f(x) / x = l $and $b \ne 0$, then $\lim_{x \to 0} f(bx)/x =bl$. Hint: Write $f(bx)/x = b[f(bx)/bx]$. 
\end{problem*}

\begin{problem*}
  \T\B 5-34 Prove that $\lim_{x \to 0^+}f(\frac{1}{x}) = \lim_{x \to \infty} f(x)$
\end{problem*}

\chapter{Calculas on Manifolds}
\section{Some proofs}
% \begin{theorem}
% Let $O \in \mathbb{R}^{n+1}$ be open. Then $O'$ is also open in $\mathbb{R}^n$
% where $O'$ is constructed by dropping the first co-ordinate from each element of
% $O$.
% \end{theorem}
% 
% \begin{proof}
% Let $x'=(x_1, \ldots, x_n) \in O'$. Then for some $\alpha \in \mathbb{R}$, we
% have $x = (\alpha, x_1, \ldots, x_n) \in O$. Then there exists an open rectangle
% $U$ containing $x$ which is inside $O$. The same open rectangle dropping the
% first coordinate contains $x'$. Now suppose $y' = (y_1, \ldots, y_n)$ in inside
% this open rectangle $U'$. Pick any $\beta \in (a,b)$ where $a,b$ comes from
% $U$'s first coordinates. Then $y = (\beta, y')$ is inside the open rectangle $U
% \subseteq O$ for some $\beta$. Therefore, $y'$ is also in $O'$. Hence $O'$ is
% open.
% \end{proof}

\begin{theorem}
  Let $O \subseteq \mathbb{R}^{n+1}$ be open and $x\in \mathbb{R}$. Let's define $O'$ as follows:
  \[
  O' = \{(y_1, \ldots, y_n) : (x,y_1, \ldots, y_n) \in O \}
  \]

  Then $O' \subseteq \mathbb{R}^n$ is open. 
\end{theorem}

\begin{proof}
  Let $(y_1, \ldots, y_n) \in O'$ be arbitrary. By definition, $(x, y_1, \ldots, y_n) \in O$. Since $O$ is open there is an open rectangle $U \subseteq O$. Corrsponding open rectangle $U'$ also contains our $y$. Now suppose $z \in U'$ is arbitrary. Then $(x, z_1, \ldots, z_n) \in U \subseteq O$. Therefore, $z \in O'$. Hence, $O'$ is open. 
\end{proof}


\begin{theorem}
  Let $O \in \mathbb{R}^{m+n}$ be open and $x = (x_1, \ldots, x_m) \in \mathbb{R}^m$. Define
  \[
  O' = \{(y_1, \ldots, y_n) : (x_1, \ldots, x_m, y_1, \ldots, y_n) \in O \}
  \]
  Then $O'$ is also open in $\mathbb{R}^n$. 
\end{theorem}

\begin{proof}
  Previous proof works with some slight changes. 
\end{proof}

\begin{theorem}
If $B \subseteq \mathbb{R}^{n}$ is compact and $x \in \mathbb{R}$, then $\{x\}\times
B \subseteq \mathbb{R}^{n+1}$ is also compact.
\end{theorem}
\begin{proof}
Suppose $O$ is an open cover for $\{x\}\times B \subseteq \mathbb{R}^{n+1}$. Then we
can construct an open cover $O'$ by having a function $f:U \to U'$ by dropping
the first coordinate. Since $B$ is compact, there is a finite list of open sets
$U_1', \ldots, U_2'$ that covers $B$. From this finite set we can find a finite
cover $U_1, \ldots, U_n$ by going back pre-image by pre-image so that we contain
$\alpha$. Hence $\{x\}\times B \in \mathbb{R}^{n+1}$ is compact.
\end{proof}


\begin{theorem}
If $B \in \mathbb{R}^{m}$ is compact and $x \in \mathbb{R}^n$, then $\{x\}\times
B \in \mathbb{R}^{n+m}$ is also compact.
\end{theorem}

\begin{proof}
  Similar as above. 
\end{proof}

\begin{theorem}
If $B$ is compact and $O$ is an open cover of $\{x\}\times B \in
\mathbb{R}^{n+m}$, then there is an open set $U\in \mathbb{R}^n$ containing $x$
such that $U \times B$ is covered by a finite number of sets in $O$.
\end{theorem}

\begin{theorem}
  If $A \subseteq \mathbb{R}^n$  and $B \subseteq \mathbb{R}^m$  are compact, then $A \times B \subseteq \mathbb{R}^{m+n}$ is compact. 
\end{theorem}

\begin{theorem}
  $A_1 \times \cdots \times A_k$ is compact if each $A_i$ is. In particular, a closed rectangle in $\mathbb{R}^k$ is compact. 
\end{theorem}

\begin{theorem}
  A closed bounded subset of $\mathbb{R}^n$ is compact. (The converse is also true (Problem 1-20)).
\end{theorem}

\begin{theorem}
  Prove the converse of Corollary 1-7: A compcat subset of $\mathbb{R}^n$ is closed and bounded (see also Problem 1-28). 
\end{theorem}

\begin{proof}
  Let $B \subseteq \mathbb{R}^n$ be compact. Boundededness of $B$ is trivial. We only have to show that $B$ is closed, we will show that $\mathbb{R}^n \setminus B$ is open. Let $p \in \mathbb{R}^n \setminus B$ be arbitrary. For each $q \in B$, we consider the open set $W_q = B_r(q, \frac{\abs{p-q}}{2})$. These consiststs of an open cover $O$ of $B$. By compactness, $W_{q_1}\ldots W_{q_m}$  covers $B$. Choose $q_i$ such that $\abs{p-q_i}$ is smallest. Then the neighbourhood $B_(p) \subseteq \mathbb{R}^n \setminus B$. Hence, $\mathbb{R}^n\setminus B$ is open. 
\end{proof}

\begin{exercise*}
1-21(a) If $A$ is closed and $x \not\in A$, prove that there is a number $d > 0$ such that $\abs{y-x} \ge d$ for all $y \in A$. 
\end{exercise*}

\begin{proof}
  Let $x \not\in A$. Since $\mathbb{R}^n \setminus A$ is open, there exists a neighborhood $B(x) \subseteq \mathbb{R}^n \setminus A$. Take $d$ as the radius of this neighborhood $B(x)$. 
\end{proof}

\begin{exercise*}
  1-21(b) If $A$ is closed, $B$ is compact, and $A \cap B = \emptyset$, prove that there is $d > 0$ such that $\abs{y-x} \ge d$ for all $y \in A$ and $x \in B$. Hint: For each $b \in B$ find an open set $U$ containing $b$ such that this relation holds for $x \in U \cap B$. 
\end{exercise*}

\begin{proof}
  Since $A$ and $B$ are disjoint, by 1-21(a) for each $b\in B$ we can find $d > 0$ such that $\abs{y -b } \ge d$ for all $y \in A$. Consider the open cover $O = \{B_{\frac{d}{2}}(b) : b \in B\}$. Since $B$ is compact, finitely many open set $B_{d_1}, \ldots B_{d_k}$ covers $B$. By triangale inequality if $x \in B_{d_i}$ then we have $\abs{y -x } \ge d_i$. By picking the minimums of $d_i$ we find our $d$. 
\end{proof}

\begin{exercise*}
  1-21(c) Give a counterexample in $\mathbb{R}^2$ if $A$ and $B$ are closed but neither is compact. 
\end{exercise*}

\begin{proof}
  Let $A = \mathbb{N}$ and $B = \{n + \frac{1}{2n} | n \in \mathbb{N} \}$. 
\end{proof}

\begin{exercise*}
  1-22 If $U$ is open and $C \subseteq U$ is compact, show that there is a
  compact set $D$ such that $C \subseteq \interior D$ and $D \subseteq U$. 
\end{exercise*}

\begin{proof}
  Notice that $U^c$ is closed and $C \cup U^c = \emptyset$. Therefore, by 1-21 there exists $d> 0$ such that $\abs{y -x } > d$ for all $x \in C$ and $y \in U^c$. Now consider the set
  \[
  E = \bigcup_{x \in C} U_x
  \]
  where $U_x$ is an open neighbourhood with radius $d/2$ and centered at $x$. Then we have $C \subseteq E \subseteq U$. Moreover since $C$ is compact we can assume that $E$ is an union of finitely many sets $U_x$. Our choice of $d$ guaruntees that if we take
  \[
  D = \bigcup_{i=1}^k\overline{U}_{x_i}
  \] 

then we still have $C \subseteq D \subseteq U$, where each $\overline{U}_{x_i}$
is a closed neighbourhood.
\end{proof}

\begin{theorem}
  If $A \subseteq \mathbb{R}^n$, a function $f : A \to \mathbb{R}^m$ is continuous if and only if for every open set $U \subseteq \mathbb{R}^m$ there is some open set $V\subseteq \mathbb{R}^n$ such that $f^{-1}(U) = V \cap A$
\end{theorem}

\begin{proof}
  We prove the converse. Let $a \in A$ be arbitrary, we show that $f$ is continuos at $a$. Let $\epsilon > 0$ be arbitrary. Then the neighbourhood $B = B_{\epsilon}(f(a)) \subseteq \mathbb{R}^m$ is open. Therefore, $f^{-1}(B) = V \cap A$  for some open set $V \subseteq \mathbb{R}^n$. But then, $a \in V$ so there is an open set $B_{\delta}(a) \subseteq V$  for some $\delta > 0$. Therefore, if $x \in B_{\delta}(a)$ and $x \in A$, then $f(x) \subseteq B$. Hence $f$ is continuous at $a$.  
\end{proof}

If $A \to \mathbb{R}$ is bounded, the extent to which $f$ fails to be continuous at $a \in A$ can be measured in a precise way. For $\delta > 0$ let

\begin{align*}
  M(a,f,\delta) &= \sup \{ f(x) : x \in A \tand  \abs{x-a} < \delta \}\\
  m(a,f,\delta) &= \inf \{ f(x) : x \in A \tand  \abs{x-a} < \delta \}\\  
\end{align*}

The oscillation $o(f,a)$ of $f$ at $a$ is defined by $o(f,a) = \displaystyle\lim_{\delta \to 0^+} [M(a,f,\delta) - m(a,f,\delta)]$

\begin{theorem}
  If $f$ is bounded, then $o(f,a) = \displaystyle\lim_{\delta \to 0^+} [M(a,f,\delta) - m(a,f,\delta)]$ always exists. 
\end{theorem}

\begin{proof}
  Consider the sequence $M(a,f,\frac{1}{n}) - m(a,f,\frac{1}{n})$. This is a decreasing sequence which is bounded below by $0$. Therefore, there exists a limit $a \ge 0$. It is easy to show

  \[
  a = \lim_{\delta \to 0^+} [M(a,f,\delta) - m(a,f,\delta)]
  \]
  since $1g(x) = M(a,f,x) - m(a,f,x)$ is a non-increasing function on $x > 0$. 
\end{proof}

\begin{exercise*}
  1-23 If $f : A \to \mathbb{R}^m$ and $a \in A$, show that $\lim_{x \to a} f(x) = b$ if and only if $\lim_{x \to a} f^i(x)= b^i$ for $i = 1,\ldots, m$. 
\end{exercise*}

\begin{proof}
  \T\B $\rightarrow$ Suppose $\lim_{x \to a} f(x) = b$, then for each $\epsilon > 0$ there exists $\delta > 0$ such that if $y \in A$ and $0 < \abs{x-y} < \delta $, then $\abs{f(x) -b } < \epsilon$. Same choice of $\delta $ ensures that $\abs{f^i(x) -b^i} < \epsilon$. 


  \T\B $\leftarrow$ Now suppose $\lim_{x \to a} f^i(x)= b^i$ for $i = 1,\ldots, m$. Let $\epsilon > 0$ be arbitrary. Then we find $\delta_1, \ldots, \delta_m$ where each $\delta_i > 0$ such that $ \abs{f^i(x) -b^i} < \epsilon$. Taking minimum of these $\delta_i$ as $\delta$ we find that $\abs{f(x) -b } \le \sum \abs{f^i(x) -b^i} \le n\epsilon$. 
\end{proof}

\begin{exercise*}
  1-24. Prove that $f: A \to \mathbb{R}^m$ is continuous at $a$ if and only if each $f^i$ is. 
\end{exercise*}

\begin{proof}
  \T\B $\rightarrow$  Suppose $f : A \to \mathbb{R}^m$ is continuous at $a$. Then $\lim_{x \to a}f(x) = f(a)$ From 1-23, we see that $\lim_{x \to a}f^i(x) = f^i(a)$.  Therefore, each $f^i: A \to \mathbb{R}$ is continuous at $a \in \mathbb{R}^n$.

  \T\B $\leftarrow$ Suppose each $f^i: A \to \mathbb{R}$ is continuous at $a \in A$. Then we have $\lim_{x \to a}f^i(x) = f^i(a)$. Again, using 1-23 we conclude that $\lim_{x \to a}f(x) = f(a)$. 
\end{proof}

\begin{exercise*}
  1-25 Prove that a linear transformation $T : \mathbb{R}^n \to \mathbb{R}^m$ is continous. Hint: Use Problem 1-10.
\end{exercise*}

\begin{proof}
  We know from 1-10 that there is a $M > 0$ such that $\abs{T(h)} \le M\abs{h}$ for all $h \in \mathbb{R}^n$. Now take $\delta = \frac{\epsilon}{2M}$. Then, for any $y \in \mathbb{R}^n$ such that $\abs{x -y } < \delta$ we have (for $h = y-x$):
  \begin{align*}
    \abs{T(y) - T(x)} &= \abs{T(x+h) - T(x)}\\
    &= \abs{T(x) + T(h) - T(x)} \\
    &= \abs{T(h)}\\
    & \le M\abs{h}\\
    & < M \frac{\epsilon}{2M} = \epsilon
  \end{align*}
\end{proof}

\section{Differentiation}
\begin{problem*}
  2-1. Prove that if $f : \mathbb{R}^n \to \mathbb{R}^m$ is differentiable at $a \in \mathbb{R}^n$, then it is continuous at $a$. Hint: User Problem 1-10. 
\end{problem*}

\begin{proof}
  Since $f$ is differentiable at $a$, it is easy to show the weaker statement
  \[
  \lim_{h\to 0} \abs{f(a+h) - f(a) - L(h)}  = 0
  \].

  Now,
  \begin{align*}
    0 \le \abs{f(a+h) - f(a) } & \le \abs{f(a+h) - f(a) - L(h)} + \abs{L(h)}
  \end{align*}

  Since both of the terms on the right side goes to $0$ as $h \to 0$, it shows that $f$ is continuous at $a$. 
\end{proof}

\begin{problem*}
  2-2. A function $f : \mathbb{R}^2 \to \mathbb{R}$ is independent of the second variable if for each $x \in \mathbb{R}$ we have $f(x, y_1) = f(x, y_2)$ for all $y_1, y_2 \in \mathbb{R}$. Show that $f$ is independent of the second variable if and only if there is a funciton $g : \mathbb{R} \to \mathbb{R}$ such that $f(x, y) = g(x)$. What is $f'(a,b$ in terms of $g'$?
\end{problem*}

\begin{proof}
  Suppose $f$ is independent of the second variable. Define
  \[
  g(x) = f(x, y) 
  \]
  Then $g$ is well defined.

  On the other hand, suppose there exists such function $g : \mathbb{R} \to \mathbb{R}$. Then $f$ is independent of the second variable. 
\end{proof}

\begin{problem*}
  2-12: A function $f : \mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R}^p$ is bilinear if for $x, x_1, x_2 \in \mathbb{R}^n$, $y, y_1, y_2 \in \mathbb{R}^m$, and $a \in \mathbb{R}$ we have
    \begin{align*}
    f(ax, y) &= af(x,y) = f(x, ay)\\
    f(x_1 + x_2 , y) &= f(x_1, y) + f(x_2, y)\\
    f(x, y_1 + y_2) &= f(x, y_1) + f(x, y_2)
  \end{align*}

    (a) Prove that if $f$ is bilinear, then
    \[
    \lim_{(h,k) \to 0} = \frac{\abs{f(h,k)}}{\abs{(h,k)}} = 0
    \]

    (b) Prove that $Df(a,b)(x,y) = f(a,y) + f(x,b)$.

    (c) Show that the formula for $Dp(a,b)$ in Theorem 2-3 is a special case of (b). 
      
\end{problem*}

\begin{proof}
  (a) We will be a little bit more verbose in our proof than the problem
  statement, and will use \emph{norm} and \emph{absolute} value sign
  properly. Let $e_1, \ldots, e_n$ be an orthonormal basis of $\mathbb{R}^n$,
  and similarly $f_1, \ldots, f_m$ ben an orthonormal basis of
  $\mathbb{R}^m$. Moreover, let $x \in \mathbb{R}^n$ and $y \in \mathbb{R}^m$
  such that :
  \begin{align*}
    x& = x_1 e_1 + \cdots + x_n e_n\\
    y& = y_1 f_1 + \cdots + y_m e_m
  \end{align*}.

  Then we have
  \begin{align*}
    f(x,y) & = \sum_{i=1}^n \sum_{j=1}^m x_i y_j f(e_i, f_j)
  \end{align*}

  Hence,
    \begin{align*}
      \norm{f(x,y)} & \le \sum_{i=1}^n \sum_{j=1}^m \abs{x_i} \abs{y_j} \norm{f(e_i, f_j)}\\
      & \le \sum_{i=1}^n \sum_{j=1}^m \norm{x} \norm{y} \norm{f(e_i, f_j)}\\
      & = \norm{x} \norm{y} \sum_{i=1}^n \sum_{j=1}^m  \norm{f(e_i, f_j)}\\
      & = C \norm{x} \norm{y}
    \end{align*}

    Therefore,

    \begin{align*}
      \frac{\norm{f(h,k)}}{\norm{(h,k)}} & \le \frac{C \norm{h} \norm{k}}{\norm{(h,k)}}
    \end{align*}

    But $\norm{h} \norm{k} \le \norm{h}^2 + \norm{k}^2 = {\norm{(h,k)}}^2$. Hence.
    \[
      \frac{\norm{f(h,k)}}{\norm{(h,k)}} \le \frac{C \norm{h} \norm{k}}{\norm{(h,k)}} \le \frac{C \norm{(h,k)}^2}{\norm{(h,k)}} \le C \norm{(h,k)}
      \]

    Therefore,
    \[
    \lim_{(h,k) \to 0} \frac{\norm{f(h,k)}}{\norm{(h,k)}} = 0
    \]
\end{proof}

\begin{proof}
  (b) \begin{align*}
    & \lim_{(x,y) \to 0}\frac{\norm{f(a+x, y+b) - f(a,b) - f(a,y) - f(x,b)}}{\norm{(x,y)}}\\
    = & \lim_{(x,y) \to 0}\frac{\norm{f(a,b) + f(a,y) + f(x,b) + f(x,y) - f(a,b) - f(a,y) - f(x,b)}}{\norm{(x,y)}}\\
    = & \lim_{(x,y) \to 0}\frac{\norm{f(x,y)}}{\norm{(x,y)}} = 0\\
  \end{align*}

  We also need to show that $Dp(a,b)(x,y) = f(a,y) + f(x,b) : \mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R}^p$ is linear, but that is easy to show. 
\end{proof}

\begin{proof}
  For $n = m = p = 1$, the product is bilinear, and follows from there. 
\end{proof}

\begin{problem*}
  2-13 Define $IP : \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}$ by $IP(x,y) = \langle x, y \rangle$.

  \T\B (a) Find $D(IP)(a,b)$ and $(IP)'(a,b)$.

  \T\B (b) If $f,g : \mathbb{R} \to \mathbb{R}^n$ are differentiable and $h : \mathbb{R} \to \mathbb{R}$ is defined by $h(t) = \langle f(t), g(t) \rangle$, show that
  \[
  h'(a) = \langle f'(a), g(a)\rangle + \langle f(a), g'(a)\rangle
  \]

  \T\B (c) If $f : \mathbb{R} \to \mathbb{R}^n$ is differentiable and $\abs{f(t)} = 1$ for all $t$, show that
  \[
  \langle f'(t), f(t) \rangle = 0
  \]

  \T\B (d) Exhibit a differentiable functoin $f : \mathbb{R} \to \mathbb{R}$ such that the function $\abs{f}$ defined by $\abs{f}(t) = \abs{f(t)}$ is not differentiable. 
\end{problem*}

\begin{proof}
  (a) $DIP(a,b)(x,y) = \ipp{a}{y} + \ipp{x}{y}$
\end{proof}

\begin{proof}
  (b) Let's define $s: \mathbb{R} \to \mathbb{R}^n  \times \mathbb{R}^n$ as follows:
  \[
  s(a) = (f(a), g(a))
  \]

  Then we have
  \[
  Ds(a)(x) = (xf'(a), xg'(a))
  \]

  Notice tht :
  \[
  h = IP \circ s
  \]

  Then by chain rule:
  \begin{align*}
    Dh(a)(x) &= DIP(s(a))\cdot Ds(a)(x) \\
    &= DIP((f(a), g(a)))(xf'(a), xg'(a)) \\
    &= \ipp{f(a)}{xg'(a)} + \ipp{xf'(a)}{g(a)}\\
    &= \left(\ipp{f(a)}{g'(a)} + \ipp{f'(a)}{g(a)}\right) x\\
  \end{align*}
\end{proof}

\begin{proof}
  Let $h(t) = \ipp{f(t)}{f(t)} = \norm{f(t)} = 1$. Then we have
  \begin{align*}
    0 = \ipp{f'(t)}{f(t)} + \ipp{f(t)}{f'(t)}
  \end{align*}

  Therefore, $\ipp{f(t)}{f'(t)} = 0$.
\end{proof}

% ----------------------------------------------------------------------
%
% ----------------------------------------------------------------------

\chapter{Linear Algebra Done right}

\section{Excercise : 3.D}

\begin{problem*}
  1. Suppose $T \in \LL(U,V)$ and $ S \in \LL(V,W)$ are both invertible
  linear maps. Prove that $ST \in \LL(U,W)$ is invertible and that $(ST)^{-1} = T^{-1}S^{-1}$
\end{problem*}

\begin{proof}
  Since $ST$ is a composition of two bijections, it is also a bijection, and hence is also a bijection. We only need to show that $(ST)^{-1} = T^{-1}S^{-1}$.

  \begin{align*}
    (T^{-1} S^{-1}) (S T) & = T^{-1} (S^{-1} S) T\\
    & = T^{-1} I T\\
    & = T^{-1}T = I \\
  \end{align*}

  Similarly, $(S T) (T^{-1} S^{-1}) = I$.
\end{proof}

\begin{problem*}9. Suppose $V$ is finite-dimensional and $S,T \in \LL(V)$. Prove that $ST$ is invertible if and only if both $S$ and $T$ are invertible.\end{problem*}

\begin{proof}
  The reverse direction is immediate from Problem 1. Now suppose that $ST$ is invertible. Let $v \in V$. Then $STv = v$. Hence $S$ is surjective and therefore invertible. Suppose that $Tu = Tv$. Then, $ST u = ST v$. Since $ST$ is invertible, we have $u = v$. Therefore, $T$ is injective, and since $V$ is finite dimension, $T$ is invertible. 
\end{proof}

\begin{problem*}10. Suppose $V$ is finite-dimensional and $S, T \in \LL(V)$. Prove that $ST = I$ if and only if $TS = I$\end{problem*}

\begin{proof}
  Suppose $ST = I$. Then $STv = v$. Since $V$ is finite dimensional, $S$ is invertible. Now,
  \begin{align*}
    I = S^{-1}S = S^{-1}(ST)S = (S^{-1}S)TS = ITS = TS
  \end{align*}
\end{proof}

\section{Exercise: 6.A}
\begin{problem*}
  (29) Suppose $V_1, \ldots, V_m$ are inner product spaces. Show that the equation 
  \[
  \langle(u_1, \ldots, u_m), (v_1, \ldots, v_m) \rangle = \langle u_1, v_1\rangle + \cdots + \langle u_m, v_m\rangle
  \]
  defines an inner product on $V_1 \times \cdot \times V_m$.
\end{problem*}


\section{Excercise : 7.C}

\begin{problem*}
4. Suppose $T \in \LL(V,W)$ Prove that $T^*T$ is a positive operator on $V$ and $TT^*$ is a positive operator on $W$. 
\end{problem*}

\begin{proof}
  \[
  (T^{*}T)^* = T^*T
  \]
  Therefore, $T^{*}T$ is self-adjoint.

  Moreover,
  \begin{align*}
    \langle T^{*}Tv, v \rangle & = \langle Tv, Tv \rangle\\
    & = ||Tv||^2 \ge 0
  \end{align*}

Therefore, $T^{*}T$ is positive. 
\end{proof}


% ======================================================================
%                       Document Ends here 
% ======================================================================
\end{document}


% Local Variables:
% compile-command: "make -k all"
% fill-column: 80
% comment-fill-column: 80
% mode: latex
% mode: reftex
% tex-main-file: "webmail.tex"
% End:
